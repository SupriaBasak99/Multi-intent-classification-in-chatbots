{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupriaBasak99/Multi-intent-classification-in-chatbots/blob/main/1_Naive_bayes_for_FYP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzG_IJGLsihI",
        "outputId": "9e5e949a-2ef2-4735-972a-d58d51045680"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize \n",
        "import re\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOY6SkkJwGus",
        "outputId": "e0db19e2-e7f9-4a82-cc98-f9f198beb767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filename):\n",
        "  df = pd.read_csv(filename, encoding = \"latin1\", names = [\"Intent\", \"Sentence\"])\n",
        "  print(df.head())\n",
        "  intent = df[\"Intent\"]\n",
        "  unique_intent = list(set(intent))\n",
        "  sentences = list(df[\"Sentence\"])\n",
        "  \n",
        "  return (intent, unique_intent, sentences)\n",
        "  "
      ],
      "metadata": {
        "id": "NrBMNgpywEQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intent, unique_intent, sentences = load_dataset(\"/content/drive/MyDrive/atis_intents_train.csv\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGc6GtmEwbb6",
        "outputId": "22c6df7a-4574-44eb-8e39-49daa5fb886c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Intent                                           Sentence\n",
            "0            intent                                           sentence\n",
            "1       atis_flight   what flights are available from pittsburgh to...\n",
            "2  atis_flight_time   what is the arrival time in san francisco for...\n",
            "3      atis_airfare            cheapest airfare from tacoma to orlando\n",
            "4      atis_airfare   round trip fares from pittsburgh to philadelp...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_intent[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBpxfQTKw3Gy",
        "outputId": "f97766f6-7c02-4056-9fe3-3a8305648c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['atis_flight', 'atis_quantity', 'atis_aircraft', 'atis_ground_service', 'atis_flight_time']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(sentences):\n",
        "  words = []\n",
        "  for s in sentences:\n",
        "    clean = re.sub(r'[^ a-z A-Z 0-9]', \" \", s)\n",
        "    w = word_tokenize(clean)\n",
        "    #stemming\n",
        "    words.append([i.lower() for i in w])\n",
        "    \n",
        "  return words "
      ],
      "metadata": {
        "id": "Q3UbA8tXHbj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_words = cleaning(sentences)\n",
        "print(len(cleaned_words))\n",
        "print(cleaned_words[:2]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaSfUoioLrtz",
        "outputId": "c4eba12f-5316-4ec8-c641-d4fc327359f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4834\n",
            "[['sentence'], ['what', 'flights', 'are', 'available', 'from', 'pittsburgh', 'to', 'baltimore', 'on', 'thursday', 'morning']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, val_X, train_Y, val_Y = train_test_split(sentences, intent, shuffle = True, test_size = 0.1)"
      ],
      "metadata": {
        "id": "r4Q3aj7CLsr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
        "  token = Tokenizer(filters = filters)\n",
        "  token.fit_on_texts(words)\n",
        "  return token"
      ],
      "metadata": {
        "id": "cMgajSzjL2Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(words):\n",
        "  return(len(max(words, key = len)))"
      ],
      "metadata": {
        "id": "beSSBoItMH95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data: \", train_X[0])\n",
        "print(\"Target: \", train_Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L75hsxDXMNjq",
        "outputId": "77b93543-1e2d-4613-eb14-e7f9f12653d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data:   i want to fly from boston to san francisco\n",
            "Target:  intent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9EJufC9TMg71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "god7tx8TM_cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cmyHW4Cqw9x"
      },
      "source": [
        "def create_model_binomial_nb():\n",
        "  vect = CountVectorizer().fit(train_X)\n",
        "  train_X_vectorized = vect.transform(train_X)\n",
        "  model = BernoulliNB()\n",
        "  model.fit(train_X_vectorized, train_Y)\n",
        "  preds = model.predict(vect.transform(val_X))\n",
        "  score = accuracy_score(val_Y, preds)\n",
        "  print(\"Accuracy: \", score)\n",
        "  f1 = f1_score(val_Y, preds, average='macro')\n",
        "  print(\"Macro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='micro')\n",
        "  print(\"Micro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='weighted')\n",
        "  print(\"Weighted F1 Score:\", f1, \"\\n\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_multinomial_nb():\n",
        "  vect = CountVectorizer().fit(train_X)\n",
        "  train_X_vectorized = vect.transform(train_X)\n",
        "  model = MultinomialNB()\n",
        "  model.fit(train_X_vectorized, train_Y)\n",
        "  preds = model.predict(vect.transform(val_X))\n",
        "  score = accuracy_score(val_Y, preds)\n",
        "  print(\"Accuracy: \", score)\n",
        "  f1 = f1_score(val_Y, preds, average='macro')\n",
        "  print(\"Macro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='micro')\n",
        "  print(\"Micro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='weighted')\n",
        "  print(\"Weighted F1 Score:\", f1, \"\\n\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "iW9gGyE6NJTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_gaussian_nb():\n",
        "  vect = CountVectorizer().fit(train_X)\n",
        "  train_X_vectorized = vect.transform(train_X)\n",
        "  model = GaussianNB()\n",
        "  model.fit(train_X_vectorized.toarray(), train_Y)\n",
        "  preds = model.predict(vect.transform(val_X).toarray())\n",
        "  score = accuracy_score(val_Y, preds)\n",
        "  print(\"Accuracy: \", score)\n",
        "  f1 = f1_score(val_Y, preds, average='macro')\n",
        "  print(\"Macro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='micro')\n",
        "  print(\"Micro F1 Score:\", f1)\n",
        "  f1 = f1_score(val_Y, preds, average='weighted')\n",
        "  print(\"Weighted F1 Score:\", f1, \"\\n\")\n",
        "  return model"
      ],
      "metadata": {
        "id": "8nwlcKIfNNbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Binomial Naive Bayes\\n\")\n",
        "model = create_model_binomial_nb()\n",
        "#Precting first entry\n",
        "#print(model.predict(np.reshape(val_X[0], (1, len(val_X[0])))))\n",
        "print(\"Multinomial Naive Bayes\\n\")\n",
        "model = create_model_multinomial_nb()\n",
        "#Precting first entry\n",
        "#print(model.predict(np.reshape(val_X[0], (1, len(val_X[0])))))\n",
        "print(\"Gaussian Naive Bayes\\n\")\n",
        "model = create_model_gaussian_nb()\n",
        "#Precting first entry\n",
        "#print(model.predict(np.reshape(val_X[0], (1, len(val_X[0])))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SO0qzH3iO57y",
        "outputId": "c45598f4-5240-4432-8608-78861bb0efbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binomial Naive Bayes\n",
            "\n",
            "Accuracy:  0.9070247933884298\n",
            "Macro F1 Score: 0.6572863189469681\n",
            "Micro F1 Score: 0.9070247933884298\n",
            "Weighted F1 Score: 0.8995287824270262 \n",
            "\n",
            "Multinomial Naive Bayes\n",
            "\n",
            "Accuracy:  0.9111570247933884\n",
            "Macro F1 Score: 0.683132178667893\n",
            "Micro F1 Score: 0.9111570247933884\n",
            "Weighted F1 Score: 0.9041409905193848 \n",
            "\n",
            "Gaussian Naive Bayes\n",
            "\n",
            "Accuracy:  0.4669421487603306\n",
            "Macro F1 Score: 0.4159144167761917\n",
            "Micro F1 Score: 0.4669421487603306\n",
            "Weighted F1 Score: 0.5292731465841312 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N6o5qV5MO524"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}